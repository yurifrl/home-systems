# apiVersion: v1
# kind: PersistentVolume
# metadata:
#   name: my-local-pv
# spec:
#   storageClassName: local-storage
#   capacity:
#     storage: 10Gi
#   accessModes:
#     - ReadWriteOnce
#   persistentVolumeReclaimPolicy: Retain
#   volumeMode: Block
#   local:
#     path: /dev/sda2
#   nodeAffinity:
#     required:
#       nodeSelectorTerms:
#         - matchExpressions:
#             - key: kubernetes.io/hostname
#               operator: In
#               values:
#                 - nixos-1
# ---
# apiVersion: ceph.rook.io/v1
# kind: CephCluster
# metadata:
#   name: rook-ceph
#   namespace: rook-ceph
# spec:
#   dataDirHostPath: /var/lib/rook
#   mon:
#     count: 1
#     allowMultiplePerNode: true
#     volumeClaimTemplate:
#       spec:
#         storageClassName: local-storage
#         resources:
#           requests:
#             storage: 5Gi
#   storage:
#     useAllNodes: false
#     useAllDevices: false
#     nodes:
#       - name: nixos-1
#         devices:
#           - name: sda2
#     storageClassDeviceSets:
#       - name: set1
#         count: 1
#         resources:
#           requests:
#             storage: 10Gi
#         volumeClaimTemplates:
#           - metadata:
#               name: data
#             spec:
#               resources:
#                 requests:
#                   storage: 10Gi
#               storageClassName: local-storage
#               volumeMode: Block
#               accessModes:
#                 - ReadWriteOnce
#   cephVersion:
#     image: quay.io/ceph/ceph:v18.2.4
#     allowUnsupported: false
#   skipUpgradeChecks: false
#   continueUpgradeAfterChecksEvenIfNotHealthy: false
#   mgr:
#     count: 1
#     allowMultiplePerNode: true
#   dashboard:
#     enabled: true
#     ssl: true
#   crashCollector:
#     disable: false
#   logCollector:
#     enabled: true
#     periodicity: daily
#     maxLogSize: 500M
#   priorityClassNames:
#     mon: system-node-critical
#     osd: system-node-critical
#     mgr: system-cluster-critical
#   disruptionManagement:
#     managePodBudgets: true
#     osdMaintenanceTimeout: 30
#     pgHealthCheckTimeout: 0
# ---
# apiVersion: ceph.rook.io/v1
# kind: CephBlockPool
# metadata:
#   name: my-block-pool
#   namespace: rook-ceph
# spec:
#   failureDomain: host
#   replicated:
#     size: 3
#     requireSafeReplicaSize: true
# ---
# apiVersion: storage.k8s.io/v1
# kind: StorageClass
# metadata:
#   name: local-storage
# provisioner: kubernetes.io/no-provisioner
# volumeBindingMode: WaitForFirstConsumer
# reclaimPolicy: Retain